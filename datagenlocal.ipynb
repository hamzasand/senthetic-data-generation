{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import pdfplumber\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Initialize the LLaMA model\n",
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Optimized function to create a prompt for Q&A generation\n",
    "def generate_prompt(text):\n",
    "    return (\n",
    "        f\"The following is a detailed medical document:\\n\\n{text}\\n\\n\"\n",
    "        f\"Generate as many insightful questions as possible based on the above text. \"\n",
    "        f\"For each question, provide a detailed and comprehensive answer that is between 200 and 250 words. \"\n",
    "        f\"Ensure the answers are informative and specific to the medical context provided.\"\n",
    "    )\n",
    "\n",
    "# Function to parse Q&A pairs from model output\n",
    "def parse_qa_pairs(output_text):\n",
    "    lines = output_text.split(\"\\n\")\n",
    "    qas = []\n",
    "    question = None\n",
    "    answer = None\n",
    "\n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"question:\"):\n",
    "            if question and answer:  # Save the previous Q&A\n",
    "                qas.append((question.strip(), answer.strip()))\n",
    "            question = line[len(\"Question:\"):].strip()\n",
    "            answer = None  # Reset answer\n",
    "        elif line.lower().startswith(\"answer:\"):\n",
    "            answer = line[len(\"Answer:\"):].strip()\n",
    "    # Add the last Q&A pair if it exists\n",
    "    if question and answer:\n",
    "        qas.append((question.strip(), answer.strip()))\n",
    "    return qas\n",
    "\n",
    "# Directory containing PDFs\n",
    "pdf_directory = \"/home/hamza/Desktop/qa_system/pdf\"\n",
    "output_csv_path = \"path/to/output/medical_qna.csv\"\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open(output_csv_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"File Name\", \"Question\", \"Answer\"])  # Write header\n",
    "\n",
    "    # Process each PDF in the directory\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_directory, filename)\n",
    "            print(f\"Processing: {filename}\")\n",
    "            \n",
    "            # Extract text from the PDF\n",
    "            extracted_text = extract_text_from_pdf(pdf_path)\n",
    "            \n",
    "            # Skip empty PDFs\n",
    "            if not extracted_text.strip():\n",
    "                print(f\"Skipped empty PDF: {filename}\")\n",
    "                continue\n",
    "\n",
    "            # Generate the prompt\n",
    "            prompt = generate_prompt(extracted_text)\n",
    "            \n",
    "            # Generate Q&A using the pipeline\n",
    "            outputs = pipeline(prompt, max_new_tokens=1024)  # Increase token limit for detailed responses\n",
    "            \n",
    "            # Parse the Q&A pairs\n",
    "            qna_text = outputs[0][\"generated_text\"]\n",
    "            qna_pairs = parse_qa_pairs(qna_text)\n",
    "            \n",
    "            # Write each Q&A pair to the CSV\n",
    "            for question, answer in qna_pairs:\n",
    "                csv_writer.writerow([filename, question, answer])\n",
    "            \n",
    "            print(f\"Processed and saved Q&A pairs for: {filename}\")\n",
    "\n",
    "print(f\"Q&A saved to CSV file: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
